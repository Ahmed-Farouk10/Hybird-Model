{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0665a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\youss\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: rich in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (13.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (2.0.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (1.26.2)\n",
      "Requirement already satisfied: namex in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\youss\\anaconda3\\lib\\site-packages (from keras) (3.6.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\youss\\anaconda3\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\youss\\anaconda3\\lib\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\youss\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02467c4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02467c4d",
    "outputId": "44b98446-6f0c-49b7-c810-ab3527f8543f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\youss\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd7f21a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dd7f21a",
    "outputId": "491335fe-fb6e-4fd8-d87e-05700c010628"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\youss\\AppData\\Local\\Temp\\ipykernel_4256\\4114148790.py:1: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"data.csv\",encoding ='latin1')\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\",encoding ='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cbe31e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "82cbe31e",
    "outputId": "2e77f73f-2292-4736-bf31-dc924ca67679"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_time</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k70vrzb</td>\n",
       "      <td>1</td>\n",
       "      <td>Lol what kind of busted translator device you ...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-29 23:59:03+00:00</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k70vk4r</td>\n",
       "      <td>1</td>\n",
       "      <td>Translation:\\n\\nAmen. Kill jews and continue g...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-29 23:57:29+00:00</td>\n",
       "      <td>-0.7177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.584</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>k70vhew</td>\n",
       "      <td>1</td>\n",
       "      <td>Friendly fact reminder: Israel has been steali...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-29 23:56:58+00:00</td>\n",
       "      <td>-0.8020</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.674</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k70ve4h</td>\n",
       "      <td>1</td>\n",
       "      <td>Well, i would never support Hamas, but there a...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-29 23:56:18+00:00</td>\n",
       "      <td>-0.7294</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.629</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>k70vay1</td>\n",
       "      <td>1</td>\n",
       "      <td>/u/TickeMeTendie. This is an automatic notice:...</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>2023-10-29 23:55:42+00:00</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.833</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id score                                          self_text  \\\n",
       "0    k70vrzb     1  Lol what kind of busted translator device you ...   \n",
       "1    k70vk4r     1  Translation:\\n\\nAmen. Kill jews and continue g...   \n",
       "2    k70vhew     1  Friendly fact reminder: Israel has been steali...   \n",
       "3    k70ve4h     1  Well, i would never support Hamas, but there a...   \n",
       "4    k70vay1     1  /u/TickeMeTendie. This is an automatic notice:...   \n",
       "\n",
       "         subreddit               created_time  Compound  Positive Negative  \\\n",
       "0  IsraelPalestine  2023-10-29 23:59:03+00:00    0.4215     0.177      0.0   \n",
       "1  IsraelPalestine  2023-10-29 23:57:29+00:00   -0.7177     0.000    0.416   \n",
       "2  IsraelPalestine  2023-10-29 23:56:58+00:00   -0.8020     0.129    0.197   \n",
       "3  IsraelPalestine  2023-10-29 23:56:18+00:00   -0.7294     0.126    0.245   \n",
       "4  IsraelPalestine  2023-10-29 23:55:42+00:00    0.4891     0.103    0.063   \n",
       "\n",
       "   Neutral  Category  \n",
       "0    0.823   Neutral  \n",
       "1    0.584  Negative  \n",
       "2    0.674  Negative  \n",
       "3    0.629  Negative  \n",
       "4    0.833   Neutral  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbaadee",
   "metadata": {
    "id": "2bbaadee"
   },
   "outputs": [],
   "source": [
    "cl = ['comment_id','score','subreddit','created_time']\n",
    "df = df.drop(columns=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e39f3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "06e39f3d",
    "outputId": "89736ed1-e504-40cf-8a4f-ac341a50937b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self_text</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lol what kind of busted translator device you ...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translation:\\n\\nAmen. Kill jews and continue g...</td>\n",
       "      <td>-0.7177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.584</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friendly fact reminder: Israel has been steali...</td>\n",
       "      <td>-0.8020</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.674</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, i would never support Hamas, but there a...</td>\n",
       "      <td>-0.7294</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.629</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/u/TickeMeTendie. This is an automatic notice:...</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.833</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           self_text  Compound  Positive  \\\n",
       "0  Lol what kind of busted translator device you ...    0.4215     0.177   \n",
       "1  Translation:\\n\\nAmen. Kill jews and continue g...   -0.7177     0.000   \n",
       "2  Friendly fact reminder: Israel has been steali...   -0.8020     0.129   \n",
       "3  Well, i would never support Hamas, but there a...   -0.7294     0.126   \n",
       "4  /u/TickeMeTendie. This is an automatic notice:...    0.4891     0.103   \n",
       "\n",
       "  Negative  Neutral  Category  \n",
       "0      0.0    0.823   Neutral  \n",
       "1    0.416    0.584  Negative  \n",
       "2    0.197    0.674  Negative  \n",
       "3    0.245    0.629  Negative  \n",
       "4    0.063    0.833   Neutral  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975a05ac",
   "metadata": {
    "id": "975a05ac"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df['Category'] = df['Category'].replace('0', 'Neutral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8750cb9f",
   "metadata": {
    "id": "8750cb9f"
   },
   "outputs": [],
   "source": [
    "# Text cleaning and preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text'] = df['self_text'].apply(preprocess_text)\n",
    "\n",
    "c = ['self_text']\n",
    "df = df.drop(columns=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6862af0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6862af0f",
    "outputId": "246b9bf0-e604-4bc2-88e9-1e0582d3dad0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>lol kind busted translator device got speak ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.584</td>\n",
       "      <td>Negative</td>\n",
       "      <td>translation amen kill jew continue gazan oppre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.8020</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.674</td>\n",
       "      <td>Negative</td>\n",
       "      <td>friendly fact reminder israel stealing palesti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.7294</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.629</td>\n",
       "      <td>Negative</td>\n",
       "      <td>well would never support hamas action israel c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.833</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>automatic notice casual comment analogy inflam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound  Positive Negative  Neutral  Category  \\\n",
       "0    0.4215     0.177      0.0    0.823   Neutral   \n",
       "1   -0.7177     0.000    0.416    0.584  Negative   \n",
       "2   -0.8020     0.129    0.197    0.674  Negative   \n",
       "3   -0.7294     0.126    0.245    0.629  Negative   \n",
       "4    0.4891     0.103    0.063    0.833   Neutral   \n",
       "\n",
       "                                          clean_text  \n",
       "0  lol kind busted translator device got speak ha...  \n",
       "1  translation amen kill jew continue gazan oppre...  \n",
       "2  friendly fact reminder israel stealing palesti...  \n",
       "3  well would never support hamas action israel c...  \n",
       "4  automatic notice casual comment analogy inflam...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rYKO_006d6L4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rYKO_006d6L4",
    "outputId": "ad79ae38-7973-4e1d-e06b-99f10f52dc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m6031/6031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 74ms/step - accuracy: 0.7561 - loss: 0.5944 - val_accuracy: 0.8395 - val_loss: 0.4051\n",
      "Epoch 2/5\n",
      "\u001b[1m6031/6031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 81ms/step - accuracy: 0.8452 - loss: 0.4089 - val_accuracy: 0.8426 - val_loss: 0.4016\n",
      "Epoch 3/5\n",
      "\u001b[1m6031/6031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 79ms/step - accuracy: 0.8795 - loss: 0.3279 - val_accuracy: 0.8361 - val_loss: 0.4303\n",
      "Epoch 4/5\n",
      "\u001b[1m6031/6031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 81ms/step - accuracy: 0.9086 - loss: 0.2534 - val_accuracy: 0.8258 - val_loss: 0.4904\n",
      "Epoch 5/5\n",
      "\u001b[1m6031/6031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 84ms/step - accuracy: 0.9316 - loss: 0.1931 - val_accuracy: 0.8205 - val_loss: 0.5805\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Category_encoded'] = label_encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['clean_text'])  # Fit tokenizer on all texts\n",
    "\n",
    "# Convert texts to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_length = 100  # Choose your max sequence length\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "embedding_dim = 100\n",
    "num_filters = 128\n",
    "kernel_size = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))  # Assuming 3 sentiment classes: Negative, Neutral, Positive\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, df['Category_encoded'], epochs=5, batch_size=64, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
